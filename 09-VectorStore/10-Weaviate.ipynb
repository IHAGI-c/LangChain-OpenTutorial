{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weaviate\n",
    "\n",
    "- Author: [Haseom Shin](https://github.com/IHAGI-c)\n",
    "- Design: []()\n",
    "- Peer Review: []()\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/13-LangChain-Expression-Language/11-Fallbacks.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/13-LangChain-Expression-Language/11-Fallbacks.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This comprehensive tutorial explores Weaviate, a powerful open-source vector database that enables efficient similarity search and semantic operations. Through hands-on examples, you'll learn:\n",
    "\n",
    "- How to set up and configure Weaviate for production use\n",
    "- Essential operations including document indexing, querying, and deletion\n",
    "- Advanced features such as hybrid search, multi-tenancy, and batch processing\n",
    "- Integration with LangChain for sophisticated applications like RAG and QA systems\n",
    "- Best practices for managing and scaling your vector database\n",
    "\n",
    "Whether you're building a semantic search engine, implementing RAG systems, or developing AI-powered applications, this tutorial provides the foundational knowledge and practical examples you need to leverage Weaviate effectively.\n",
    "\n",
    "> [Weaviate](https://weaviate.io/) is an open-source vector database. It allows you to store data objects and vector embeddings from your favorite ML-models, and scale seamlessly into billions of data objects.\n",
    "\n",
    "To use this integration, you need to have a running Weaviate database instance.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Credentials](#credentials)\n",
    "  - [Setting up Weaviate Cloud Services](#setting-up-weaviate-cloud-services)\n",
    "- [What is Weaviate?](#what-is-weaviate)\n",
    "- [Why Use Weaviate?](#why-use-weaviate)\n",
    "- [Initialization](#initialization)\n",
    "  - [Creating Collections in Weaviate](#creating-collections-in-weaviate)\n",
    "  - [Delete Collection](#delete-collection)\n",
    "  - [List Collections](#list-collections)\n",
    "  - [Data Preprocessing](#data-preprocessing)\n",
    "  - [Document Preprocessing Function](#document-preprocessing-function)\n",
    "- [Manage vector store](#manage-vector-store)\n",
    "  - [Add items to vector store](#add-items-to-vector-store)\n",
    "  - [Delete items from vector store](#delete-items-from-vector-store)\n",
    "- [Finding Objects by Similarity](#finding-objects-by-similarity)\n",
    "  - [Step 1: Preparing Your Data](#step-1-preparing-your-data)\n",
    "  - [Step 2: Perform the search](#step-2-perform-the-search)\n",
    "  - [Quantify Result Similarity](#quantify-result-similarity)\n",
    "- [Search mechanism](#search-mechanism)\n",
    "- [Persistence](#persistence)\n",
    "- [Multi-tenancy](#multi-tenancy)\n",
    "- [Retriever options](#retriever-options)\n",
    "- [Use with LangChain](#use-with-langchain)\n",
    "  - [Question Answering with Sources](#question-answering-with-sources)\n",
    "  - [Retrieval-Augmented Generation](#retrieval-augmented-generation)\n",
    "\n",
    "\n",
    "### References\n",
    "- [Langchain-Weaviate](https://python.langchain.com/docs/integrations/providers/weaviate/)\n",
    "- [Weaviate Documentation](https://weaviate.io/developers/weaviate)\n",
    "- [Weaviate Introduction](https://weaviate.io/developers/weaviate/introduction)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"openai\",\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"tiktoken\",\n",
    "        \"langchain-weaviate\",\n",
    "        \"langchain-openai\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"WEAVIATE_API_KEY\": \"\",\n",
    "        \"WEAVIATE_URL\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"Weaviate\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively set `OPENAI_API_KEY` in `.env` file and load it. \n",
    "\n",
    "[Note] This is not necessary if you've already set `OPENAI_API_KEY` in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credentials\n",
    "\n",
    "There are three main ways to connect to Weaviate:\n",
    "\n",
    "1. **Local Connection**: Connect to a Weaviate instance running locally through Docker\n",
    "2. **Weaviate Cloud(WCD)**: Use Weaviate's managed cloud service\n",
    "3. **Custom Deployment**: Deploy Weaviate on Kubernetes or other custom configurations\n",
    "\n",
    "For this notebook, we'll use Weaviate Cloud (WCD) as it provides the easiest way to get started without any local setup.\n",
    "\n",
    "### Setting up Weaviate Cloud Services\n",
    "\n",
    "1. First, sign up for a free account at [Weaviate Cloud Console](https://console.weaviate.cloud)\n",
    "2. Create a new cluster\n",
    "3. Get your API key\n",
    "4. Set API key\n",
    "5. Connect to your WCD cluster\n",
    "\n",
    "#### 1. Weaviate Signup\n",
    "![Weaviate Cloud Console](./assets/10-weaviate-credentials-01.png)\n",
    "\n",
    "#### 2. Create Cluster\n",
    "![Weaviate Cloud Console](./assets/10-weaviate-credentials-02.png)\n",
    "![Weaviate Cloud Console](./assets/10-weaviate-credentials-03.png)\n",
    "\n",
    "#### 3. Get API Key\n",
    "**If you using gRPC, please copy the gRPC URL**\n",
    "\n",
    "![Weaviate Cloud Console](./assets/10-weaviate-credentials-04.png)\n",
    "\n",
    "#### 4. Set API Key\n",
    "```\n",
    "WEAVIATE_API_KEY=\"YOUR_WEAVIATE_API_KEY\"\n",
    "WEAVIATE_URL=\"YOUR_WEAVIATE_CLUSTER_URL\"\n",
    "```\n",
    "\n",
    "#### 5. Connect to your WCD cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from utils.weaviate_vectordb import WeaviateDB\n",
    "\n",
    "weaviate_url = os.environ.get(\"WEAVIATE_URL\")\n",
    "weaviate_api_key = os.environ.get(\"WEAVIATE_API_KEY\")\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "weaviate_db = WeaviateDB(url=weaviate_url, api_key=weaviate_api_key, openai_api_key=openai_api_key, embeddings=embeddings)\n",
    "client = weaviate_db.connect()\n",
    "\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Weaviate?\n",
    "\n",
    "Weaviate is a powerful open-source vector database that revolutionizes how we store and search data. It combines traditional database capabilities with advanced machine learning features, allowing you to:\n",
    "\n",
    "- Weaviate is an open source [vector database](https://weaviate.io/blog/what-is-a-vector-database).\n",
    "- Weaviate allows you to store and retrieve data objects based on their semantic properties by indexing them with [vectors](./concepts/vector-index.md).\n",
    "- Weaviate can be used stand-alone (aka _bring your vectors_) or with a variety of [modules](./modules/index.md) that can do the vectorization for you and extend the core capabilities.\n",
    "- Weaviate has a [GraphQL-API](./api/graphql/index.md) to access your data easily.\n",
    "- Weaviate is fast (check our [open source benchmarks](./benchmarks/index.md)).\n",
    "\n",
    "> 💡 **Key Feature**: Weaviate achieves millisecond-level query performance, making it suitable for production environments.\n",
    "\n",
    "## Why Use Weaviate?\n",
    "\n",
    "Weaviate stands out for several reasons:\n",
    "\n",
    "1. **Versatility**: Supports multiple media types (text, images, etc.)\n",
    "2. **Advanced Features**:\n",
    "   - Semantic Search\n",
    "   - Question-Answer Extraction\n",
    "   - Classification\n",
    "   - Custom ML Model Integration\n",
    "3. **Production-Ready**: Built in Go for high performance and scalability\n",
    "4. **Developer-Friendly**: Multiple access methods through GraphQL, REST, and various client libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "Before initializing our vector store, let's connect to a Weaviate collection. If one named index_name doesn't exist, it will be created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Collections in Weaviate\n",
    "\n",
    "The `create_collection` function establishes a new collection in Weaviate, configuring it with specified properties and vector settings. This foundational operation requires six key parameters:\n",
    "\n",
    "**Required Parameters:**\n",
    "- `client`: Weaviate client instance for database connection\n",
    "- `collection_name`: Unique identifier for your collection\n",
    "- `description`: Detailed description of the collection's purpose\n",
    "- `properties`: List of property definitions for data schema\n",
    "- `vectorizer`: Configuration for vector embedding generation\n",
    "- `metric`: Distance metric for similarity calculations\n",
    "\n",
    "**Advanced Configuration Options:**\n",
    "- For custom distance metrics: Utilize the `VectorDistances` class\n",
    "- For alternative vectorization: Leverage the `Configure.Vectorizer` class\n",
    "\n",
    "**Example Usage:**\n",
    "```python\n",
    "properties = [\n",
    "    Property(name=\"text\", data_type=DataType.TEXT),\n",
    "    Property(name=\"title\", data_type=DataType.TEXT)\n",
    "]\n",
    "vectorizer = Configure.Vectorizer.text2vec_openai()\n",
    "create_collection(client, \"Documents\", \"Document storage\", properties, vectorizer)\n",
    "```\n",
    "\n",
    "> **Note:** Choose your distance metric and vectorizer carefully as they significantly impact search performance and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the `create_collection` function to create the collection we'll use in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'BookChunk' created successfully.\n"
     ]
    }
   ],
   "source": [
    "from weaviate.classes.config import Property, DataType, Configure\n",
    "\n",
    "collection_name = \"BookChunk\"  # change if desired\n",
    "description = \"A chunk of a book's content\"\n",
    "vectorizer = Configure.Vectorizer.text2vec_openai(\n",
    "    model=\"text-embedding-3-large\"\n",
    ")  # You can select other vectorizer\n",
    "metric = \"dot\"  # You can select other distance metric\n",
    "properties = [\n",
    "    Property(\n",
    "        name=\"text\", data_type=DataType.TEXT, description=\"The content of the text\"\n",
    "    ),\n",
    "    Property(\n",
    "        name=\"order\",\n",
    "        data_type=DataType.INT,\n",
    "        description=\"The order of the chunk in the book\",\n",
    "    ),\n",
    "    Property(\n",
    "        name=\"title\", data_type=DataType.TEXT, description=\"The title of the book\"\n",
    "    ),\n",
    "    Property(\n",
    "        name=\"author\", data_type=DataType.TEXT, description=\"The author of the book\"\n",
    "    ),\n",
    "    Property(\n",
    "        name=\"source\", data_type=DataType.TEXT, description=\"The source of the book\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "weaviate_db.create_collection(\n",
    "    client, collection_name, description, properties, vectorizer, metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Collection\n",
    "\n",
    "Managing collections in Weaviate includes the ability to remove them when they're no longer needed. The `delete_collection` function provides a straightforward way to remove collections from your Weaviate instance.\n",
    "\n",
    "**Function Signature:**\n",
    "- `client`: Weaviate client instance for database connection\n",
    "- `collection_name`: Name of the collection to be deleted\n",
    "\n",
    "**Advanced Operations:**\n",
    "For batch operations or managing multiple collections, you can use the `delete_all_collections()` function, which removes all collections from your Weaviate instance.\n",
    "\n",
    "> **Important:** Collection deletion is permanent and cannot be undone. Always ensure you have appropriate backups before deleting collections in production environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted index: BookChunk\n"
     ]
    }
   ],
   "source": [
    "# weaviate_db.delete_all_collections(client)    # if you want to delete all collections, uncomment this line\n",
    "weaviate_db.delete_collection(client, collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Collections\n",
    "\n",
    "Lists all collections in Weaviate, providing a comprehensive view of your database schema and configurations. The `list_collections` function helps you inspect and manage your Weaviate instance's structure.\n",
    "\n",
    "**Key Information Returned:**\n",
    "- Collection names\n",
    "- Collection descriptions\n",
    "- Property configurations\n",
    "- Data types for each property\n",
    "\n",
    "> **Note:** This operation is particularly useful for database maintenance, debugging, and documentation purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collections (indexes) in the Weaviate schema:\n",
      "- Collection name: LangChain_178c8b97ed6b47e08524f99a42507d9b\n",
      "  Description: No description available\n",
      "  Properties:\n",
      "    - Name: text, Type: DataType.TEXT\n",
      "    - Name: order, Type: DataType.NUMBER\n",
      "    - Name: source, Type: DataType.TEXT\n",
      "    - Name: author, Type: DataType.TEXT\n",
      "    - Name: title, Type: DataType.TEXT\n",
      "\n",
      "- Collection name: AI_Collection\n",
      "  Description: This property was generated by Weaviate's auto-schema feature on Tue Feb  4 12:29:21 2025\n",
      "  Properties:\n",
      "    - Name: text, Type: DataType.TEXT\n",
      "    - Name: metadata, Type: DataType.OBJECT\n",
      "    - Name: unique_key, Type: DataType.TEXT\n",
      "\n",
      "- Collection name: LangChain_53e31c7099854e06a3718b74d8bd974a\n",
      "  Description: No description available\n",
      "  Properties:\n",
      "    - Name: text, Type: DataType.TEXT\n",
      "    - Name: order, Type: DataType.NUMBER\n",
      "    - Name: source, Type: DataType.TEXT\n",
      "    - Name: author, Type: DataType.TEXT\n",
      "    - Name: title, Type: DataType.TEXT\n",
      "\n",
      "- Collection name: BookChunk\n",
      "  Description: A chunk of a book's content\n",
      "  Properties:\n",
      "    - Name: text, Type: DataType.TEXT\n",
      "    - Name: order, Type: DataType.INT\n",
      "    - Name: title, Type: DataType.TEXT\n",
      "    - Name: author, Type: DataType.TEXT\n",
      "    - Name: source, Type: DataType.TEXT\n",
      "\n",
      "- Collection name: LangChain_b164393f671d4b0ba354c38e6e053282\n",
      "  Description: No description available\n",
      "  Properties:\n",
      "    - Name: text, Type: DataType.TEXT\n",
      "    - Name: title, Type: DataType.TEXT\n",
      "    - Name: order, Type: DataType.TEXT\n",
      "    - Name: source, Type: DataType.TEXT\n",
      "    - Name: author, Type: DataType.TEXT\n",
      "\n",
      "- Collection name: My_collection\n",
      "  Description: This property was generated by Weaviate's auto-schema feature on Tue Feb  4 11:48:44 2025\n",
      "  Properties:\n",
      "    - Name: unique_key, Type: DataType.TEXT\n",
      "    - Name: text, Type: DataType.TEXT\n",
      "    - Name: metadata, Type: DataType.OBJECT\n",
      "\n",
      "- Collection name: LangChain_79b0e6f413f44286baff724ce696708f\n",
      "  Description: No description available\n",
      "  Properties:\n",
      "    - Name: text, Type: DataType.TEXT\n",
      "    - Name: author, Type: DataType.TEXT\n",
      "    - Name: title, Type: DataType.TEXT\n",
      "    - Name: order, Type: DataType.TEXT\n",
      "    - Name: source, Type: DataType.TEXT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weaviate_db.list_collections(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<weaviate.Collection config={\n",
      "  \"name\": \"BookChunk\",\n",
      "  \"description\": \"A chunk of a book's content\",\n",
      "  \"generative_config\": null,\n",
      "  \"inverted_index_config\": {\n",
      "    \"bm25\": {\n",
      "      \"b\": 0.75,\n",
      "      \"k1\": 1.2\n",
      "    },\n",
      "    \"cleanup_interval_seconds\": 60,\n",
      "    \"index_null_state\": false,\n",
      "    \"index_property_length\": false,\n",
      "    \"index_timestamps\": false,\n",
      "    \"stopwords\": {\n",
      "      \"preset\": \"en\",\n",
      "      \"additions\": null,\n",
      "      \"removals\": null\n",
      "    }\n",
      "  },\n",
      "  \"multi_tenancy_config\": {\n",
      "    \"enabled\": false,\n",
      "    \"auto_tenant_creation\": false,\n",
      "    \"auto_tenant_activation\": false\n",
      "  },\n",
      "  \"properties\": [\n",
      "    {\n",
      "      \"name\": \"text\",\n",
      "      \"description\": \"The content of the text\",\n",
      "      \"data_type\": \"text\",\n",
      "      \"index_filterable\": true,\n",
      "      \"index_range_filters\": false,\n",
      "      \"index_searchable\": true,\n",
      "      \"nested_properties\": null,\n",
      "      \"tokenization\": \"word\",\n",
      "      \"vectorizer_config\": {\n",
      "        \"skip\": false,\n",
      "        \"vectorize_property_name\": true\n",
      "      },\n",
      "      \"vectorizer\": \"text2vec-openai\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"order\",\n",
      "      \"description\": \"The order of the chunk in the book\",\n",
      "      \"data_type\": \"int\",\n",
      "      \"index_filterable\": true,\n",
      "      \"index_range_filters\": false,\n",
      "      \"index_searchable\": false,\n",
      "      \"nested_properties\": null,\n",
      "      \"tokenization\": null,\n",
      "      \"vectorizer_config\": {\n",
      "        \"skip\": false,\n",
      "        \"vectorize_property_name\": true\n",
      "      },\n",
      "      \"vectorizer\": \"text2vec-openai\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"title\",\n",
      "      \"description\": \"The title of the book\",\n",
      "      \"data_type\": \"text\",\n",
      "      \"index_filterable\": true,\n",
      "      \"index_range_filters\": false,\n",
      "      \"index_searchable\": true,\n",
      "      \"nested_properties\": null,\n",
      "      \"tokenization\": \"word\",\n",
      "      \"vectorizer_config\": {\n",
      "        \"skip\": false,\n",
      "        \"vectorize_property_name\": true\n",
      "      },\n",
      "      \"vectorizer\": \"text2vec-openai\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"author\",\n",
      "      \"description\": \"The author of the book\",\n",
      "      \"data_type\": \"text\",\n",
      "      \"index_filterable\": true,\n",
      "      \"index_range_filters\": false,\n",
      "      \"index_searchable\": true,\n",
      "      \"nested_properties\": null,\n",
      "      \"tokenization\": \"word\",\n",
      "      \"vectorizer_config\": {\n",
      "        \"skip\": false,\n",
      "        \"vectorize_property_name\": true\n",
      "      },\n",
      "      \"vectorizer\": \"text2vec-openai\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"source\",\n",
      "      \"description\": \"The source of the book\",\n",
      "      \"data_type\": \"text\",\n",
      "      \"index_filterable\": true,\n",
      "      \"index_range_filters\": false,\n",
      "      \"index_searchable\": true,\n",
      "      \"nested_properties\": null,\n",
      "      \"tokenization\": \"word\",\n",
      "      \"vectorizer_config\": {\n",
      "        \"skip\": false,\n",
      "        \"vectorize_property_name\": true\n",
      "      },\n",
      "      \"vectorizer\": \"text2vec-openai\"\n",
      "    }\n",
      "  ],\n",
      "  \"references\": [],\n",
      "  \"replication_config\": {\n",
      "    \"factor\": 1,\n",
      "    \"async_enabled\": false,\n",
      "    \"deletion_strategy\": \"NoAutomatedResolution\"\n",
      "  },\n",
      "  \"reranker_config\": null,\n",
      "  \"sharding_config\": {\n",
      "    \"virtual_per_physical\": 128,\n",
      "    \"desired_count\": 1,\n",
      "    \"actual_count\": 1,\n",
      "    \"desired_virtual_count\": 128,\n",
      "    \"actual_virtual_count\": 128,\n",
      "    \"key\": \"_id\",\n",
      "    \"strategy\": \"hash\",\n",
      "    \"function\": \"murmur3\"\n",
      "  },\n",
      "  \"vector_index_config\": {\n",
      "    \"quantizer\": null,\n",
      "    \"cleanup_interval_seconds\": 300,\n",
      "    \"distance_metric\": \"dot\",\n",
      "    \"dynamic_ef_min\": 100,\n",
      "    \"dynamic_ef_max\": 500,\n",
      "    \"dynamic_ef_factor\": 8,\n",
      "    \"ef\": -1,\n",
      "    \"ef_construction\": 128,\n",
      "    \"filter_strategy\": \"sweeping\",\n",
      "    \"flat_search_cutoff\": 40000,\n",
      "    \"max_connections\": 32,\n",
      "    \"skip\": false,\n",
      "    \"vector_cache_max_objects\": 1000000000000\n",
      "  },\n",
      "  \"vector_index_type\": \"hnsw\",\n",
      "  \"vectorizer_config\": {\n",
      "    \"vectorizer\": \"text2vec-openai\",\n",
      "    \"model\": {\n",
      "      \"baseURL\": \"https://api.openai.com\",\n",
      "      \"model\": \"text-embedding-3-large\"\n",
      "    },\n",
      "    \"vectorize_collection_name\": true\n",
      "  },\n",
      "  \"vectorizer\": \"text2vec-openai\",\n",
      "  \"vector_config\": null\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "print(weaviate_db.lookup_collection(collection_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Before storing documents in Weaviate, it's essential to preprocess them into manageable chunks. This section demonstrates how to effectively prepare your documents using the `RecursiveCharacterTextSplitter` for optimal vector storage and retrieval.\n",
    "\n",
    "**Key Preprocessing Steps:**\n",
    "- Text chunking for better semantic representation\n",
    "- Metadata assignment for enhanced searchability\n",
    "- Document structure optimization\n",
    "- Batch preparation for efficient storage\n",
    "\n",
    "> **Note:** While this example uses `RecursiveCharacterTextSplitter`, choose your text splitter based on your specific content type and requirements. The chunk size and overlap parameters significantly impact search quality and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a long document we can split up.\n",
    "with open(\"./data/the_little_prince.txt\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='The Little Prince\\nWritten By Antoine de Saiot-Exupery (1900〜1944)'), Document(metadata={}, page_content='[ Antoine de Saiot-Exupery ]'), Document(metadata={}, page_content='Over the past century, the thrill of flying has inspired some to perform remarkable feats of daring. For others, their desire to soar into the skies led to dramatic leaps in technology. For Antoine de Saint-Exupéry, his love of aviation inspired stories, which have touched the hearts of millions'), Document(metadata={}, page_content='have touched the hearts of millions around the world.'), Document(metadata={}, page_content='Born in 1900 in Lyons, France, young Antoine was filled with a passion for adventure. When he failed an entrance exam for the Naval Academy, his interest in aviation took hold. He joined the French Army Air Force in 1921 where he first learned to fly a plane. Five years later, he would leave the'), Document(metadata={}, page_content='Five years later, he would leave the military in order to begin flying air mail between remote settlements in the Sahara desert.'), Document(metadata={}, page_content=\"For Saint-Exupéry, it was a grand adventure - one with dangers lurking at every corner. Flying his open cockpit biplane, Saint-Exupéry had to fight the desert's swirling sandstorms. Worse, still, he ran the risk of being shot at by unfriendly tribesmen below. Saint-Exupéry couldn't have been more\"), Document(metadata={}, page_content=\"Saint-Exupéry couldn't have been more thrilled. Soaring across the Sahara inspired him to spend his nights writing about his love affair with flying.\"), Document(metadata={}, page_content='When World War II broke out, Saint-Exupéry rejoined the French Air Force. After Nazi troops overtook France in 1940, Saint-Exupéry fled to the United States. He had hoped to join the U. S. war effort as a fighter pilot, but was dismissed because of his age. To console himself, he drew upon his'), Document(metadata={}, page_content='To console himself, he drew upon his experiences over the Saharan desert to write and illustrate what would become his most famous book, The Little Prince (1943). Mystical and enchanting, this small book has fascinated both children and adults for decades. In the book, a pilot is stranded in the')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=40,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "split_docs = text_splitter.create_documents([raw_text])\n",
    "\n",
    "print(split_docs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Preprocessing Function\n",
    "\n",
    "The `preprocess_documents` function transforms pre-split documents into a format suitable for Weaviate storage. This utility function handles both document content and metadata, ensuring proper organization of your data.\n",
    "\n",
    "**Function Parameters:**\n",
    "- `split_docs`: List of LangChain Document objects containing page content and metadata\n",
    "- `metadata`: Optional dictionary of additional metadata to include with each chunk\n",
    "\n",
    "**Processing Steps:**\n",
    "- Iterates through Document objects\n",
    "- Assigns sequential order numbers\n",
    "- Combines document metadata with additional metadata\n",
    "- Formats data for Weaviate ingestion\n",
    "\n",
    "> **Best Practice:** When preprocessing documents, always maintain consistent metadata structure across your collection. This ensures efficient querying and filtering capabilities later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'The Little Prince\\nWritten By Antoine de Saiot-Exupery (1900〜1944)',\n",
       "  'order': 1,\n",
       "  'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupéry',\n",
       "  'source': 'Original Text'},\n",
       " {'text': '[ Antoine de Saiot-Exupery ]',\n",
       "  'order': 2,\n",
       "  'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupéry',\n",
       "  'source': 'Original Text'},\n",
       " {'text': 'Over the past century, the thrill of flying has inspired some to perform remarkable feats of daring. For others, their desire to soar into the skies led to dramatic leaps in technology. For Antoine de Saint-Exupéry, his love of aviation inspired stories, which have touched the hearts of millions',\n",
       "  'order': 3,\n",
       "  'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupéry',\n",
       "  'source': 'Original Text'},\n",
       " {'text': 'have touched the hearts of millions around the world.',\n",
       "  'order': 4,\n",
       "  'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupéry',\n",
       "  'source': 'Original Text'},\n",
       " {'text': 'Born in 1900 in Lyons, France, young Antoine was filled with a passion for adventure. When he failed an entrance exam for the Naval Academy, his interest in aviation took hold. He joined the French Army Air Force in 1921 where he first learned to fly a plane. Five years later, he would leave the',\n",
       "  'order': 5,\n",
       "  'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupéry',\n",
       "  'source': 'Original Text'},\n",
       " {'text': 'Five years later, he would leave the military in order to begin flying air mail between remote settlements in the Sahara desert.',\n",
       "  'order': 6,\n",
       "  'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupéry',\n",
       "  'source': 'Original Text'},\n",
       " {'text': \"For Saint-Exupéry, it was a grand adventure - one with dangers lurking at every corner. Flying his open cockpit biplane, Saint-Exupéry had to fight the desert's swirling sandstorms. Worse, still, he ran the risk of being shot at by unfriendly tribesmen below. Saint-Exupéry couldn't have been more\",\n",
       "  'order': 7,\n",
       "  'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupéry',\n",
       "  'source': 'Original Text'},\n",
       " {'text': \"Saint-Exupéry couldn't have been more thrilled. Soaring across the Sahara inspired him to spend his nights writing about his love affair with flying.\",\n",
       "  'order': 8,\n",
       "  'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupéry',\n",
       "  'source': 'Original Text'},\n",
       " {'text': 'When World War II broke out, Saint-Exupéry rejoined the French Air Force. After Nazi troops overtook France in 1940, Saint-Exupéry fled to the United States. He had hoped to join the U. S. war effort as a fighter pilot, but was dismissed because of his age. To console himself, he drew upon his',\n",
       "  'order': 9,\n",
       "  'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupéry',\n",
       "  'source': 'Original Text'},\n",
       " {'text': 'To console himself, he drew upon his experiences over the Saharan desert to write and illustrate what would become his most famous book, The Little Prince (1943). Mystical and enchanting, this small book has fascinated both children and adults for decades. In the book, a pilot is stranded in the',\n",
       "  'order': 10,\n",
       "  'title': 'The Little Prince',\n",
       "  'author': 'Antoine de Saint-Exupéry',\n",
       "  'source': 'Original Text'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def preprocess_documents(\n",
    "    split_docs: List[Document], metadata: Dict[str, str] = None\n",
    ") -> List[Dict[str, Dict[str, object]]]:\n",
    "    \"\"\"\n",
    "    Processes a list of pre-split documents into a format suitable for storing in Weaviate.\n",
    "\n",
    "    :param split_docs: List of LangChain Document objects (each containing page_content and metadata).\n",
    "    :param metadata: Additional metadata to include in each chunk (e.g., title, source).\n",
    "    :return: A list of dictionaries, each representing a chunk in the format:\n",
    "             {'properties': {'text': ..., 'order': ..., ...metadata}}\n",
    "    \"\"\"\n",
    "    processed_chunks = []\n",
    "    texts = []\n",
    "    metadatas = []\n",
    "    # Iterate over Document objects\n",
    "    for idx, doc in enumerate(split_docs, start=1):\n",
    "        # Extract text from page_content and include metadata\n",
    "        chunk_data = {\"text\": doc.page_content, \"order\": idx}\n",
    "        # Combine with metadata from Document and additional metadata if provided\n",
    "        if metadata:\n",
    "            chunk_data.update(metadata)\n",
    "        if doc.metadata:\n",
    "            chunk_data.update(doc.metadata)\n",
    "\n",
    "        # Format for Weaviate\n",
    "        processed_chunks.append(chunk_data)\n",
    "        texts.append(doc.page_content)\n",
    "        metadatas.append(metadata)\n",
    "\n",
    "    return processed_chunks, texts, metadatas\n",
    "\n",
    "\n",
    "metadata = {\n",
    "    \"title\": \"The Little Prince\",\n",
    "    \"author\": \"Antoine de Saint-Exupéry\",\n",
    "    \"source\": \"Original Text\",\n",
    "}\n",
    "\n",
    "processed_chunks, texts, metadatas = preprocess_documents(split_docs, metadata=metadata)\n",
    "\n",
    "processed_chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage vector store\n",
    "Once you have created your vector store, we can interact with it by adding and deleting different items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Items to Vector Store\n",
    "\n",
    "Weaviate provides flexible methods for adding documents to your vector store. This section explores two efficient approaches: standard insertion and parallel batch processing, each optimized for different use cases.\n",
    "\n",
    "#### Standard Insertion\n",
    "Best for smaller datasets or when processing order is important:\n",
    "- Sequential document processing\n",
    "- Automatic UUID generation\n",
    "- Built-in duplicate handling\n",
    "- Real-time progress tracking\n",
    "\n",
    "#### Parallel Batch Processing\n",
    "Optimized for large-scale document ingestion:\n",
    "- Multi-threaded processing\n",
    "- Configurable batch sizes\n",
    "- Concurrent execution\n",
    "- Enhanced throughput\n",
    "\n",
    "**Configuration Options:**\n",
    "- `batch_size`: Control memory usage and processing chunks\n",
    "- `max_workers`: Adjust concurrent processing threads\n",
    "- `unique_key`: Define document identification field\n",
    "- `show_progress`: Monitor ingestion progress\n",
    "\n",
    "**Performance Tips:**\n",
    "- For datasets < 1000 documents: Use standard insertion\n",
    "- For datasets > 1000 documents: Consider parallel processing\n",
    "- Monitor memory usage when increasing batch size\n",
    "- Adjust worker count based on available CPU cores\n",
    "\n",
    "> **Best Practice:** Choose your ingestion method based on dataset size and system resources. Start with conservative batch sizes and gradually optimize based on performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.util import generate_uuid5\n",
    "\n",
    "def generate_ids(collection_name: str, unique_values: List[str]):\n",
    "  ids = []\n",
    "\n",
    "  for unique_value in unique_values:\n",
    "    ids.append(generate_uuid5(collection_name, unique_value))\n",
    "  return ids\n",
    "\n",
    "ids = generate_ids(collection_name, [str(processed_chunk[\"order\"]) for processed_chunk in processed_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1/5\n",
      "Processed batch 2/5\n",
      "Processed batch 3/5\n",
      "Processed batch 4/5\n",
      "Processed batch 5/5\n",
      "\n",
      "Processing complete\n",
      "Number of successfully processed documents: 458\n",
      "Total elapsed time: 193.35 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "# Example usage\n",
    "results = weaviate_db.upsert(\n",
    "    texts=texts,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids,\n",
    "    collection_name=collection_name,\n",
    "    batch_size=100,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nProcessing complete\")\n",
    "print(f\"Number of successfully processed documents: {len(results)}\")\n",
    "print(f\"Total elapsed time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete\n",
      "Number of successfully processed documents: 458\n",
      "Total elapsed time: 280.08 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = weaviate_db.upsert_parallel(\n",
    "    texts=texts,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids,\n",
    "    collection_name=collection_name,\n",
    "    text_key=\"text\",\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nProcessing complete\")\n",
    "print(f\"Number of successfully processed documents: {len(results)}\")\n",
    "print(f\"Total elapsed time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search items from Weaviate\n",
    "\n",
    "You can search items from `weaviate` by filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'The Little Prince', 'author': 'Antoine de Saint-Exupéry', 'source': 'Original Text', 'order': 9, 'uuid': 'c78af9d2-00b1-5637-9904-f925cb8e2107'}, page_content='To console himself, he drew upon his experiences over the Saharan desert to write and illustrate what would become his most famous book, The Little Prince (1943). Mystical and enchanting, this small book has fascinated both children and adults for decades. In the book, a pilot is stranded in the'),\n",
       " Document(metadata={'title': 'The Little Prince', 'order': 10, 'source': 'Original Text', 'author': 'Antoine de Saint-Exupéry', 'uuid': '00d8fa75-c17d-5d21-8820-0175c0d461d1'}, page_content='In the book, a pilot is stranded in the midst of the Sahara where he meets a tiny prince from another world traveling the universe in order to understand life. In the book, the little prince discovers the true meaning of life. At the end of his conversation with the Little Prince, the aviator')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weaviate_db.search(\n",
    "    query=\"What is the little prince about?\",\n",
    "    filters={\"author\": \"Antoine de Saint-Exupéry\"},\n",
    "    k=2,\n",
    "    collection_name=collection_name,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete items from Weaviate\n",
    "\n",
    "You can delete items from `weaviate` by filter\n",
    "\n",
    "First, let's search for documents that contain the text `Hum! Hum!` in the `text` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'The Little Prince', 'author': 'Antoine de Saint-Exupéry', 'source': 'Original Text', 'order': 199, 'uuid': 'bef162c8-9707-5016-b1b4-3fe66a35f32b'}, page_content='\"Hum! Hum!\" replied the king; and before saying anything else he consulted a bulky almanac. \"Hum! Hum! That will be about-- about-- that will be this evening about twenty minutes to eight. And you will see how well I am obeyed.\"'),\n",
       " Document(metadata={'title': 'The Little Prince', 'order': 185, 'source': 'Original Text', 'author': 'Antoine de Saint-Exupéry', 'uuid': 'dd0f094c-35e4-5fbd-b24c-8a638b06cb77'}, page_content='\"Hum! Hum!\" replied the king. \"Then I-- I order you sometimes to yawn and sometimes to--\"\\nHe sputtered a little, and seemed vexed.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weaviate_db.keyword_search(\n",
    "    query=\"Hum! Hum!\",\n",
    "    filters={\"author\": \"Antoine de Saint-Exupéry\"},\n",
    "    k=2,\n",
    "    collection_name=collection_name,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's delete the document with the filter applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weaviate_db.delete(collection_name=collection_name, ids=None, filters={\"author\": \"Antoine de Saint-Exupéry\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the document was deleted properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weaviate_db.keyword_search(\n",
    "    query=\"Hum! Hum!\",\n",
    "    filters={\"author\": \"Antoine de Saint-Exupéry\"},\n",
    "    k=2,\n",
    "    collection_name=collection_name,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job, now let's dive into Similarity Search with Langchain Vector Store.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Objects by Similarity\n",
    "\n",
    "Weaviate allows you to find objects that are semantically similar to your query. Let's walk through a complete example, from importing data to executing similarity searches.\n",
    "\n",
    "### Step 1: Preparing Your Data\n",
    "\n",
    "Before we can perform similarity searches, we need to populate our Weaviate instance with data. We'll start by loading and chunking a text file into manageable pieces.\n",
    "\n",
    "> 💡 **Tip**: Breaking down large texts into smaller chunks helps optimize vector search performance and relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b1668975-239b-4480-815e-d1cde72d9bd0',\n",
       " '27d82cd5-ee33-4a81-a921-1fca200c9d26',\n",
       " '8ebfa9c7-051c-4e16-847e-5a817cf9c05e',\n",
       " 'a8833c86-b892-4f8b-94e6-132017e3dfba',\n",
       " '14fdd047-17e9-49e9-a6fa-4c33bcf9bd58',\n",
       " 'b6be91f8-466f-4f82-af2f-775331ddd855',\n",
       " 'de094044-e4a3-498a-80d7-8404ca0feaf3',\n",
       " '958b1462-8260-465b-8c65-fda4e7523d27',\n",
       " '44580c29-9a46-401c-a687-6f367c031b9a',\n",
       " 'e275e602-956e-4799-bc97-6cde04c5e9cd',\n",
       " 'e84b6453-5f85-4db7-a19d-a9367b37907f',\n",
       " '3ca0518e-0564-4433-982e-2f5e24b65e16',\n",
       " '2dd29e8a-bb21-4474-b30b-44814eb08d4b',\n",
       " 'c846d381-bb13-413a-8c98-6377ee16ec73',\n",
       " '4bc0188a-d229-457b-8510-d95678a5c99c',\n",
       " '2d4bf444-6c4b-413d-a0df-a418893acafa',\n",
       " '08da3328-c212-43bc-bc1b-73c5de2b524c',\n",
       " '4beb0ac1-b27b-4883-b913-36ade46845f3',\n",
       " 'e78711cc-c68c-4fb6-9492-e92f4f90c0c0',\n",
       " '159b09a9-578c-49ad-b125-6c17398898ad',\n",
       " 'dd517987-08fa-4e7d-8ff0-f2bda04010b7',\n",
       " '76631ce6-8820-4e06-a830-1ad422ad31a8',\n",
       " '9d5672bd-2763-4295-bf54-eb25244dc513',\n",
       " '33261b7a-96a9-4fc9-b6ea-aca3640831a2',\n",
       " 'c536d3cd-cf4f-49d6-975d-a52cdc430de1',\n",
       " '2d12d229-d72a-49bf-afa6-7a811afa33d2',\n",
       " 'cc78c650-69a5-4c8a-add1-e73f3c264373',\n",
       " '8533067e-1d35-42b5-b97e-fafc7f93fd69',\n",
       " 'd817e8c3-7d43-486e-9d7a-8405267a4e72',\n",
       " '089a64e1-6d2b-4da2-bb9f-336dfc24fb9d',\n",
       " '4f68c485-7a88-4fb9-ac88-37792927bd4b',\n",
       " 'bb57dc05-2360-420f-95ab-58cb6bbe9103',\n",
       " 'd3079558-2e08-4eb5-977a-9708d0d29545',\n",
       " '801a3f0d-41d8-47f0-9247-d55ad6f3a57f',\n",
       " 'dcd73075-531e-45ed-832f-f38dc7ea79ed',\n",
       " '2808b5bf-c08a-48fa-874e-153e80c8a878',\n",
       " '8d5560b7-55db-4e8c-8bad-8584dd7be793',\n",
       " '413529c2-14ff-4067-af64-59a20c59bc4b',\n",
       " 'ec470449-64d3-4b14-9a68-0d328ae4b26a',\n",
       " '5d61c4a5-d322-4d2b-8561-b52e3a5df717',\n",
       " 'c986bfa6-12d6-4130-847e-f559be606c57',\n",
       " '50d5f772-9fa4-4ae4-a2e4-481119eefa0c',\n",
       " 'ad3a1fa8-9f7a-48f5-ab58-e9f492e9775d',\n",
       " '7c20d135-3af3-42ae-adfb-e5957bcd080f',\n",
       " 'b84a1fc7-bdd0-4efb-97a9-7d2629ebe7da',\n",
       " 'e11865c3-bee3-448a-9dce-3ee046d8c716',\n",
       " '4fb9dd8f-4d94-4f0a-97d4-aca629e920d9',\n",
       " '6f3e0bc6-e18c-43ba-935e-6aa2cd1c0982',\n",
       " '1bd66fb0-df8d-47b3-a36a-b1b689cd505d',\n",
       " '1036b4a3-9c99-4855-a82c-00cbed9c42e8',\n",
       " '593006dc-0fbb-454b-ac9f-57ae7b9c856c',\n",
       " '9bb0897a-564a-458e-8603-26a6f99953b0',\n",
       " '0c20ca66-609f-43d2-a9f4-0cacaa61cab9',\n",
       " '5bb9110e-0d58-417c-b17d-453127e2c030',\n",
       " 'bb7723f1-9053-4d11-8e62-da7e1e766274',\n",
       " 'd283e07d-a564-463e-80da-3fde0e371162',\n",
       " 'c7593267-5ab7-4d90-8d76-b4def1567ade',\n",
       " '59869c0d-5629-48dd-82b1-f3fe52cbdf77',\n",
       " '9ac5993b-6250-4ec2-b828-e85255583c16',\n",
       " '5ee84e3f-143c-4bc8-9248-705064dcd3f4',\n",
       " 'fa7a8665-fc8a-45cc-b814-215855bdc419',\n",
       " '2e221ed6-0c04-4770-8368-b3a19d34cacd',\n",
       " '222dbe85-2bed-4c4e-a666-6975d20e1c88',\n",
       " '9f83419e-001d-4dfe-8ffe-ce7d0cac7f83',\n",
       " '6f775656-032d-489b-9228-6966794c419d',\n",
       " 'f5323ab1-e8ba-4400-b8bb-d727f8d1bed2',\n",
       " 'ab717322-fd09-4684-a03f-f8a40a7b9d3e',\n",
       " '47bd089f-b6cc-4836-8b4d-4ddf15249af9',\n",
       " '9ad21b7a-1467-4dda-aa73-a090dbdde740',\n",
       " 'aef06e89-f4a8-4cf9-8963-50d479c63206',\n",
       " 'a298f9b6-3cea-4b3a-849f-d6cbd3da9b01',\n",
       " '462263ab-6988-43ed-8a17-da58fcaf0277',\n",
       " '6faf04c7-ff41-4e7f-bd0e-35acec4e88ee',\n",
       " 'd98835d6-3dc7-4775-b7a0-5177a9c4ed89',\n",
       " '57cecde9-d935-4497-9df8-3d277582fa04',\n",
       " 'b9ce1340-c285-48dd-ab28-18c3866043de',\n",
       " 'f50136e4-0593-43b4-b899-71f2aebb841e',\n",
       " '7fa06870-9b2a-4692-a6e1-097eb7b5d359',\n",
       " 'dac27b29-bb16-478d-abb3-fb7c60f8ab2e',\n",
       " '6abd9061-b4e4-40f1-bcc0-2d8c9109440c',\n",
       " 'f16501b1-bb15-464f-8145-3564d565756f',\n",
       " '4276841a-7927-47bf-8405-b2e637db0606',\n",
       " 'b16d4933-c495-49d0-89e5-5f59945e7e86',\n",
       " '995faee9-1968-4fb5-89f0-f9ce3138d71c',\n",
       " '0ab20102-c196-4e46-a321-e393dce331d8',\n",
       " 'c1ef748b-3b7d-41b1-9c39-c523e4f64da3',\n",
       " '3eb582a2-a6d8-4822-aac8-e0a904749261',\n",
       " '6c7140ae-e6fa-4267-8928-da88dda55254',\n",
       " 'b1c10352-6b8c-484d-a661-76d1ca371e24',\n",
       " 'bf577b53-a83c-4913-85d6-1dd809488ce4',\n",
       " 'e5af73b5-c11a-4388-807a-ceb660030620',\n",
       " '794b6c27-bcf1-417e-807e-6e4465992de4',\n",
       " 'a3494722-b4bd-483a-a723-87c7dcdf93d9',\n",
       " '31acce81-ae9f-41e1-9c22-7c78e54d59f8',\n",
       " 'eba37124-a491-41e2-8e8a-1ea95eff01c6',\n",
       " '3aa31b9a-4af2-4ea2-b2f7-3a4dcd7c754d',\n",
       " '21651d51-6a60-4693-928d-1f9613ce4f95',\n",
       " '48e515bb-f4dc-46d4-8ba3-0ba8b2a45144',\n",
       " '40684120-ad52-44d6-9648-95183eaf563d',\n",
       " '88b300ac-5ae3-455c-bb85-b18ce057912d',\n",
       " 'f33162df-9086-48f0-a85c-2a34f4227e03',\n",
       " '80e4a767-ec3e-4aed-9ce4-24997eeb57cc',\n",
       " '31998a40-92b9-4584-ab2d-2fe8c6318d0d',\n",
       " '3d70e4fb-0c1e-4940-922b-dc67f9bd13d0',\n",
       " 'ae17cdad-19d9-4e30-b73c-dc7c9ab58967',\n",
       " '0a9d16b2-fcb5-4490-bedb-bb3fbcb2a322',\n",
       " '0636b29d-9025-467f-a75c-5ae38e4413d3',\n",
       " '68906fe6-94d3-4407-b14a-6f5ca32e4986',\n",
       " 'c3f9e9e2-d9f2-4ec1-b559-f628c0066fd5',\n",
       " '78499009-b619-4513-8312-1e024a3bc876',\n",
       " 'ca1ff971-dfe0-4055-9ee8-55bfcfc13535',\n",
       " '5679a9a0-5e32-488d-b2d9-ccbf8c743a0c',\n",
       " '251a5f4b-f886-483a-8cce-5ffe1dc20a2f',\n",
       " 'c688a7c2-5ba0-4c67-9ed6-a3e8956256d1',\n",
       " '1098d320-4793-4ae4-97e6-8fecf0153dfb',\n",
       " 'd1ca6206-14ae-4d5f-82ac-4439bc76ea83',\n",
       " 'efa81937-5a69-4417-b7e0-d4733c043252',\n",
       " 'f5be7da5-705e-405e-8ce8-1820ec8afeba',\n",
       " '75b3750d-ccf2-4e9e-9cbc-d27321c53ab2',\n",
       " 'd8ee9b17-bee6-47ea-b8d5-705f4c817759',\n",
       " '34500880-71d8-4b29-9ded-4e831ebc6b5b',\n",
       " '98450138-a866-462b-ab0d-fe4cb6dea73a',\n",
       " 'c749cf0f-7274-42c2-a844-007abbb28650',\n",
       " '2bb6aba8-4aae-4be2-b2d4-a58484d97f55',\n",
       " '55edba1a-44a9-4050-afa3-96da6bb2bd0c',\n",
       " '5d345b42-e32a-4f01-8215-cbe47de525b0',\n",
       " '6c8992d8-3983-4456-b96f-9c8abeb225a6',\n",
       " '424d781b-f7e0-4c24-a238-926cae673de3',\n",
       " '05c2561e-fd4f-4a25-9917-29c4198ff8c0',\n",
       " '10bf5003-36ca-4394-b14a-c655acb3ae56',\n",
       " '87e5ea89-b3cf-43e0-8ee3-36c7da88e7db',\n",
       " 'e6c7aaf8-ae90-4c74-92c1-2d62f70df2ec',\n",
       " '346c0e2c-26b8-4337-b0ca-9f225c50ac3f',\n",
       " 'b247aa06-e82f-4536-b575-8482b74efe99',\n",
       " 'ef3fac6f-0686-43c9-b29b-a110a5c9e9ef',\n",
       " '2e12d227-fb88-4962-bc1e-029ca8e7a665',\n",
       " 'd22d6ab7-eab9-43d9-a81d-8979a9a7e8eb',\n",
       " '03a79233-1575-4bf9-81e5-50d2d9e55ba1',\n",
       " 'dea5bfc3-bf50-49f4-8435-70c4befb6e56',\n",
       " '85e393c4-8aa0-4a24-8c76-d08084a59e7b',\n",
       " '2e96dadf-04e0-409f-baa5-10049048cb7c',\n",
       " '4c6e1c39-bc99-4567-98d0-6893735c6c82',\n",
       " '8be5326e-5521-414b-9ef6-55032739a6fe',\n",
       " 'd9d5faad-28dc-4fe8-a1a5-90ec22e6b36e',\n",
       " '55d03964-e23b-4582-b0a2-0329a7a6fba1',\n",
       " 'c898aef5-f908-4c51-a9ce-0155c2b9419d',\n",
       " 'e13f8b06-229f-4fdc-a250-449c6e601f23',\n",
       " '1b862bf9-ad01-43d5-a8db-5acdeddee093',\n",
       " 'd94ce5f3-a1a4-49a8-8422-61d1bb5e295e',\n",
       " 'e47f77fb-0ef6-4899-a0a8-6f19d83b407a',\n",
       " '0ef634f3-2ec5-4b0c-99e6-0e22737b3bda',\n",
       " '6709c85a-c10d-495d-bb8c-c98ed5217e2b',\n",
       " 'e80b0669-e75c-40f5-a24a-8acab29c5115',\n",
       " '16fe17a6-dd14-44d5-9117-7b97e606699f',\n",
       " '04ad3b98-fd88-41fc-8894-c7deed7ae251',\n",
       " 'a8bdeffe-f35b-44cb-a452-b735055db2b0',\n",
       " 'ac305d48-cdd5-4cd4-95b8-8c3a9bba3fa0',\n",
       " '4acee96a-3f4a-406b-9976-55e0ac99046c',\n",
       " 'b76bdd02-410c-4342-85d3-965ec78da92a',\n",
       " '5421d31e-2684-485a-9f07-6f24df87940d',\n",
       " '32592eb3-7bd6-42af-8794-fb7877db686d',\n",
       " '45b4bada-2ace-40c3-b997-9daac0663354',\n",
       " 'aed9a175-b3e4-40bb-b8a5-dcc18fe6225b',\n",
       " 'd5dfe3bb-c9cf-44f1-9562-da38859ea58b',\n",
       " '0e08d5e0-e057-4a0d-b509-7ef133edb560',\n",
       " '0a554ad0-7b24-482c-8c32-c5abf397f59d',\n",
       " '09c8fb19-8b40-4129-879f-87d7964f1c22',\n",
       " 'f54acb6f-1f24-453e-969e-e611ef8c076b',\n",
       " 'cee9f493-d3e9-426e-aa40-a7e16235c5af',\n",
       " 'f30bdc9c-6a61-4fa2-a034-3c34ecb86e0f',\n",
       " '49e9da25-8ec6-4576-85ae-2a9fe6bcb173',\n",
       " 'bd8ad258-6930-43fc-8b5a-a001a895e504',\n",
       " 'ef1e1191-ce27-499d-9005-111fe204cd55',\n",
       " '77b13ae3-6607-4d34-bc32-18c95a766a53',\n",
       " 'c950759b-c51c-4cc3-8dda-c38de94ec225',\n",
       " 'bf884780-76fc-46dc-9749-2eb27d52226f',\n",
       " 'f239475c-2424-4897-9a92-a3b7f04d9b39',\n",
       " '73c0e805-9514-476b-ac95-d8851fa0cfb2',\n",
       " 'eb7a978f-5f5a-40a1-bd0c-79bac81e0eff',\n",
       " 'ffa64734-4637-40c4-9e6a-24e976d625d8',\n",
       " '8d77333d-3cf5-44c3-8d34-e4c35de97ef3',\n",
       " '54e904f3-967c-4cac-8952-a6134e1928ad',\n",
       " '6565d5d0-0b48-46bd-9b26-bb0eb456af3d',\n",
       " '6f3448ff-7c06-4034-8933-3c4d3a92f5b4',\n",
       " 'a6f3b598-8c77-4e2f-8728-b713d62a95b2',\n",
       " '113ef851-05d1-447b-9e3c-d6f56a84c882',\n",
       " '6e544b0e-cacc-449d-b004-48a08d3120a2',\n",
       " 'e47baa70-4219-47e0-933a-7552178f6816',\n",
       " '280f5cd9-6b5c-4d1a-9d75-f1e3de7440b0',\n",
       " '70b47a6a-5994-4c54-a0b2-5bb9ff10e722',\n",
       " '5b1f5e2e-6fd5-46e8-a7f8-0a5277ca83c2',\n",
       " '9b1bb538-a862-4389-a1b9-7a4b84154012',\n",
       " 'd9bd5a05-7fbd-4541-998f-4c875d008d69',\n",
       " '3b6110db-7389-4d38-8836-893cc3968821',\n",
       " '7c05ea69-d03a-4d99-8f3e-4f4991d9a568',\n",
       " 'a52dbd77-f9e7-4e85-afce-24128851930e',\n",
       " '948d3f32-9b8a-40a9-b1e8-fef4e99e328f',\n",
       " 'd6d29fd8-8136-4817-a678-05a5278ec011',\n",
       " 'b123487c-ecdb-419c-8d42-472137577159',\n",
       " '41ab411c-758f-400b-ba07-d72e41972e5b',\n",
       " 'e97dc92c-3535-4edc-bb49-c5f02256cc67',\n",
       " 'fce52802-f629-4f02-9392-704ba9087d52',\n",
       " 'cee99406-efcf-4742-82c5-c8f8f3714555',\n",
       " 'e3873e7a-be32-4635-9546-0d73b75fc65f',\n",
       " '6b4bc6fc-85f3-477c-a706-1943141ec364',\n",
       " '0b09c2c0-2516-4f01-bbef-fc7c73fa6b88',\n",
       " '7169f718-d7f2-4d75-a90f-edf4f9dceda8',\n",
       " 'da28c8d6-b60f-4888-8aa0-3eb0fe7b55f2',\n",
       " 'c4e913b8-a36f-4548-b6a4-22511367ce9e',\n",
       " '27ca28da-4aa9-4171-8ce0-70e93de76c92',\n",
       " '7e445233-1c5c-4bd5-a3c4-acc7a40bde00',\n",
       " '48d86fe1-9a81-4bd7-89d6-79c7a02f6ece',\n",
       " '6098fbec-7c93-4c71-bd6c-3d17a4f90848',\n",
       " '96dfc5ac-c91d-44a4-8ff2-7839f9490e19',\n",
       " 'c2cfb3fa-97eb-415e-bb8d-ec6edb7e520e',\n",
       " '1b31fca5-036f-4841-8560-48e42755a74e',\n",
       " '61570a0a-2910-4aca-8f38-eaa5a22dec6d',\n",
       " '8a24958e-7223-4774-9b16-47fdd5eb783c',\n",
       " 'f527dad1-d78a-4436-8167-5c8ffd31fd2d',\n",
       " 'cfe6f12c-3a86-452f-b96b-4a45b131f355',\n",
       " '17ab2897-93f5-4e1b-a057-8c6eaf21937f',\n",
       " 'fd6f72b9-cdca-4c90-b142-2bf79ed7b74b',\n",
       " '37f4f761-0fb9-4bfe-a6f7-0e8bcd391893',\n",
       " '46616a5c-a389-423a-b2b8-fd5aca6dcd62',\n",
       " 'aa70eb1c-339b-4453-8232-5b73e6aef4bc',\n",
       " '7b6ec274-e9fa-47f7-a3ca-65b46b275fcf',\n",
       " 'd946cf12-fb86-4b86-894a-9f81227a3417',\n",
       " '7d51337f-8e9c-4528-83f0-a3d4dd909232',\n",
       " '7dc807cf-dad0-40d8-8ee8-fa2bef9a06c5',\n",
       " '6f72a055-e536-47b1-a6d3-5368f5624a5d',\n",
       " 'e517ec68-ccdd-4d7b-b8b0-8c08fd3fe575',\n",
       " 'dcc04c70-45f4-40c3-8901-736e30d053b0',\n",
       " 'c3886531-4039-4b24-9cc6-ae74c5bfdef4',\n",
       " '3d4c20df-7bc1-49a6-9a52-1e1e996f4310',\n",
       " '051471bf-bd5f-4e04-a4e0-a6f0ffb13479',\n",
       " 'f4f78554-ea51-437e-b47c-bab32cacfcdc',\n",
       " '6bd4dbcf-5d2a-494b-810b-a09b5a964a18',\n",
       " '1ddaeeae-8fc3-4174-8b5e-615675932b7a',\n",
       " 'ed44825b-bda8-493e-86e6-004a428d610a',\n",
       " '9576c6db-4090-498e-9deb-b68f2a61f3e9',\n",
       " '0b2d03ff-07db-496b-bf73-35fe07177741',\n",
       " '1b2480c2-d39d-445b-b616-32fb71fd5026',\n",
       " 'beca99dc-2a6e-41e0-aa4b-55c9a60049aa',\n",
       " '784fb71a-65b9-4eae-88ed-a7f785832ce1',\n",
       " '7be34816-5eab-46cb-b3ba-cc51a022768d',\n",
       " 'a0da0f2d-b0b1-4fef-93fe-ffcfc777fefb',\n",
       " 'e50bfa17-9b8b-4b20-98ba-3f029f6a7e58',\n",
       " '8a3fcf1e-5e10-4857-9630-ce798be506c4',\n",
       " '4efecae2-bcec-49e0-91d7-77b32ea76c13',\n",
       " '64532c06-79e0-49f5-83af-7f9746ae9ee4',\n",
       " '6d273bd5-90bd-4354-9aa4-a8c5cfcdc386',\n",
       " '3be9f0f1-cea7-44b8-98b0-4c3cccbe1bae',\n",
       " '695f2f33-b705-462b-abc9-dfb5afac09ea',\n",
       " 'a9aaaebc-7342-4da1-9a10-32f6e7a4cdc2',\n",
       " 'b92a57a2-febc-4ae6-a4c3-c563845a8da4',\n",
       " '57af0781-adbf-487c-9c34-3a00a08e2d51',\n",
       " '7911dd94-c743-4cf7-a0cc-db52098c10b1',\n",
       " '8af82fd1-a3d7-4baa-a206-9086b88044f6',\n",
       " '4127a936-a0c8-4fdb-a05b-887f3433dc08',\n",
       " 'c23546b0-7a31-4094-b193-062b9eefa08e',\n",
       " '97247e93-9dd9-4191-b3d7-7dab2a946ab7',\n",
       " '77a171c3-682b-41b1-97fd-588b1b05bb0c',\n",
       " '71e5ee5f-08d2-445b-adae-5f6b5f0c1940',\n",
       " '1b8a100a-c195-4363-8b22-454ad47e50b2',\n",
       " '64a57608-9d11-45d2-ac88-08fc8e03ae1b',\n",
       " 'bcb71eb9-254c-4c09-9c14-699c19511d49',\n",
       " '3c0dedac-ca26-4f4f-80a2-3b90f62c2fe9',\n",
       " 'efca2f5c-3fd7-4549-979b-838486773105',\n",
       " '66bc4552-9219-4d09-b04a-69af7aa8e60d',\n",
       " '6f6c70dc-e277-4871-96d5-22f6588af530',\n",
       " '7f8c6b7c-269a-40c7-84ca-3dd7b639845c',\n",
       " 'f924e076-a42a-4e38-a276-99b131c42693',\n",
       " '15b47dbd-cf2a-4a5c-aae5-1fc4a2923226',\n",
       " '516722fa-5718-4371-aeab-6a163ed1081f',\n",
       " '52ac6547-4aa5-4c5e-8326-149c91914ad1',\n",
       " '5fee1332-a921-4c0c-b2c3-4434f97ab4a3',\n",
       " '7323f1b8-5140-4e29-8f70-b995945c5dfd',\n",
       " '570d6fe9-c555-4e51-afb7-6fae0632a3b7',\n",
       " '67a6ca17-f646-4a72-85fc-1614752e1662',\n",
       " '5f2785bf-e5a8-4111-9990-efad5b51a6c9',\n",
       " '72f98bc4-e7d0-46cf-98be-7b13b5eb6da5',\n",
       " '2a470c6b-af1f-4845-ae96-4605645a208d',\n",
       " 'c590eef4-7074-4755-ad7c-9af4f2bc313b',\n",
       " '82c61624-88b5-4b56-979c-3695b90d7db8',\n",
       " 'd37da2ce-c717-4c24-b2fa-4bcc46005fd4',\n",
       " 'a86f79f9-0ead-4c18-946c-09d5d348f9b6',\n",
       " '1f6bc77d-2b18-4d95-abac-d3bf1575018f',\n",
       " '0d00dc07-b653-4b8e-a5d9-51321d4a1028',\n",
       " '9980d494-2b63-4b7c-9968-efff57048b79',\n",
       " 'ec945850-6de4-4735-8b8f-f089389fa1c5',\n",
       " 'e50bb339-6ea6-4eb7-9703-75b84582b332',\n",
       " '8bd477b5-7ee9-470f-85f5-7c79cf2abc31',\n",
       " '118fa770-ac11-436c-b2da-8dfa04edcbc7',\n",
       " 'dbde6d74-159c-4bf4-9121-fd807433d105',\n",
       " '15ae28b4-bcfd-41fe-89b6-445144810d99',\n",
       " '96cc4fd5-d8fc-4e5e-be1e-8865ffd3874f',\n",
       " 'bfd79b3d-5d57-4c4b-b568-8775e72a2a2b',\n",
       " 'ee9a7597-08f8-4896-99f0-16064fb788b6',\n",
       " '1902c0dd-2c76-4b38-b21d-a7b625304eac',\n",
       " 'f4fbaeac-c3c6-4c41-8a19-0309c17fefb3',\n",
       " '560e6e62-c30f-4c85-9619-1b0d4b559b9e',\n",
       " 'd6fb31c3-d1b6-40c6-93f6-cb4a6c22bda4',\n",
       " '5202d1bc-b533-4ea7-99b2-e06676142fe4',\n",
       " '15c4267a-257b-4a1b-b5a7-6314771ed7d0',\n",
       " 'b30aa411-ed47-47d4-a545-3287190c94d7',\n",
       " 'd4f6f729-227e-470e-a12e-f91ea13ab5d9',\n",
       " '1432db48-7f07-416c-bc8f-97b4855bc892',\n",
       " '92815949-14c1-4469-8b4a-e350013ac17c',\n",
       " 'da02ba33-b32e-4623-9cf7-1a8766b6cd3c',\n",
       " 'e8672a17-a993-4ca9-8789-f58c71d4b795',\n",
       " '65988e34-4eab-4e81-b5cf-51b2b6789603',\n",
       " 'eb0ba0cc-3ef3-477e-b59a-613e52d217f9',\n",
       " '600cfd27-713d-4ca6-8825-0ec5f728e825',\n",
       " '8510441a-571e-4d27-8466-7dc7077cad61',\n",
       " 'eaaea01c-62ff-493f-a88e-d5e4f8d13437',\n",
       " '0bf39eba-a1e4-47bc-973b-516476f00531',\n",
       " '533ca057-d343-4fb0-906e-07d440ee06b4',\n",
       " 'a7d4b376-900c-4705-a896-cf53ffbeacef',\n",
       " '9161e899-224e-4e28-bdff-99bd10f2bfab',\n",
       " 'a06da9df-1bb6-4b8c-b2e5-c1d5c16a8714',\n",
       " '86d391e4-d047-43d1-8b9b-5f967ee976b3',\n",
       " '3895d53e-1769-4f74-b4c4-dfc607d52641',\n",
       " '07d97288-19ee-4e86-8e82-6a643dcdc36b',\n",
       " '135bcf5a-13e8-4cc3-91e1-4a7e80578ff2',\n",
       " '1829659c-1908-43dd-83fd-b7e418319453',\n",
       " 'dba4562a-d5f4-4f9f-a11a-73c5560acc46',\n",
       " '98acb896-6367-4b53-a4fa-18876a2947a3',\n",
       " 'af1effe0-b729-4e4b-89d4-a704fc97d0de',\n",
       " 'd93de586-3400-4b97-aeaa-4bfae8da086b',\n",
       " '0027a35b-ec32-4831-8ac0-cb6cb04b5693',\n",
       " 'fe6cfc02-cbe4-4b81-a6bf-fced29dae6d3',\n",
       " '06a5e296-37d8-4efe-88e3-dc4e8395236c',\n",
       " '47d0207d-8a2c-4825-b04f-9d1c74a420c6',\n",
       " '82a04581-018d-4475-aa05-aec09a68e44b',\n",
       " '5c078591-2534-4ab8-9d6b-14b275e78ef5',\n",
       " '2bc08464-6d18-408c-a83b-46045ecd9b41',\n",
       " 'c74f76c7-029f-4e3a-a0ae-651392903fb8',\n",
       " '85fb3179-64e5-4e14-abc1-05310f414319',\n",
       " '6eaee739-dd8c-457c-a69a-a295aef615c9',\n",
       " '1daeaa70-bd00-4779-9078-0c3b67014d7b',\n",
       " '19072b4b-a538-4612-b680-b452af5df9ad',\n",
       " 'f54ac0aa-07bd-41d2-a360-8fe0e4c2e5bc',\n",
       " '5486c2e6-4a91-49a4-be1e-11ca981420b6',\n",
       " '43c79343-a98d-4273-ad97-896a233167e6',\n",
       " '175a6a91-310b-421e-8d17-aad92740bf68',\n",
       " '991c461b-3393-4878-b6df-6df0c82d6576',\n",
       " 'c849debe-542c-4b2e-a5ff-8ae1e5835ad8',\n",
       " '8eff52f0-290d-4f45-a9dc-0fe8d24791af',\n",
       " '38ad9c82-ad33-4d08-93c1-f0929550e44c',\n",
       " 'e5216578-97df-4e83-87b5-200eb589b613',\n",
       " '49d60dd9-9e98-4077-bb89-d5f6fcea07be',\n",
       " 'a38899e1-cc83-4c45-b96f-e737d0fee5cf',\n",
       " 'df5575be-d40c-411b-951a-ae5a9fe6d13a',\n",
       " 'b2a0362b-dd09-4095-a9a2-9cd80197dabe',\n",
       " 'ad5da393-33b4-4d97-81de-d1d8e27b130a',\n",
       " 'f2c2f165-0496-49ea-b73b-75ccc3f55f0f',\n",
       " 'b8dd91ac-2d75-4b51-97cc-6937de09bc4f',\n",
       " 'd41dea16-3c8b-4d69-bc07-d9bf14129652',\n",
       " '8ab066f1-861b-44d0-b38d-bb361b220182',\n",
       " '901c1c17-2b21-459f-981a-2fa0a13e62dc',\n",
       " '1890c65e-5f32-484c-980e-fa6beac5d2de',\n",
       " '4079fa64-0ca9-4c9b-b600-76b0bc1892e2',\n",
       " 'b905ca56-4b96-4e41-bf9d-418f54befc22',\n",
       " '91bd423d-0ec2-4f29-a470-1ebd692d15ce',\n",
       " 'f2fc43d6-0783-4f0c-ba3a-cf9c7b5c5706',\n",
       " '7b56312f-f8a9-49b2-bad9-a060aa463da5',\n",
       " '7715df86-598a-4855-b9dc-4828c21f110c',\n",
       " 'ab0bd9e0-e473-4c2d-aae4-17cf6edfdbe8',\n",
       " '6bbb5d04-9d37-4944-bcb7-b0edd792dc9a',\n",
       " 'b8502490-22de-4fbd-9713-76d5c349f668',\n",
       " 'a4c567e9-4318-424b-b82e-432b1108142d',\n",
       " 'cfa4e414-e72e-49cc-9b68-d4ac03afdfce',\n",
       " '8187840d-4949-4f2e-89e9-522993dc796d',\n",
       " 'c13b46d5-59f5-4e54-a26d-eb0c70448ed9',\n",
       " '263cd0b9-087f-44f9-a88f-c08d05810fb1',\n",
       " '2e6ed6da-38df-4060-ba4d-b16a25bc26d0',\n",
       " '08146ae0-f10c-4c47-88ec-bfee7a35dc1b',\n",
       " 'd5cf1108-e3aa-40f1-a778-2f98eaa53c04',\n",
       " '0b0cae29-8881-4cf3-a4ba-cc2eb878c68f',\n",
       " 'c21951d4-eed6-41ed-9d86-bf066d81d4d4',\n",
       " '423efa51-ee8a-4fce-bb62-72dab61ae8e4',\n",
       " 'c6d43baf-e633-42a0-b27d-5e1a7f9c04d2',\n",
       " '08d02dd8-aab3-44b3-89dd-82ed68a11c7f',\n",
       " 'f769a9c8-e25f-4b2d-947a-87f11c89bd31',\n",
       " 'ee663e1f-90bd-420f-a700-4591f986890f',\n",
       " '5d37669f-a3df-48c5-891c-c9fd160b997e',\n",
       " '8358a6af-2ee0-406a-bb49-022d82e6d4cd',\n",
       " '1d029f44-c020-4ad8-b000-bfc4d1adef88',\n",
       " 'eb04bb13-9f09-4582-a087-f273e58f40d1',\n",
       " '2211663d-c068-4e74-8875-8ece925153af',\n",
       " '5a521c04-e0ce-4bd7-9e46-d74a7d7d2c08',\n",
       " 'a0d07b34-692f-414e-81f7-62439076cde1',\n",
       " '1ad60a27-098d-4af6-a67d-77768bf78d6e',\n",
       " 'f88cbc78-df25-4274-8658-4026bf18602e',\n",
       " '066a0498-6139-4953-b379-62391524cef1',\n",
       " '93909d98-edc0-4eec-b068-f9890b9498e5',\n",
       " 'f3bb1d1b-6f14-419c-930b-766ac4bfb274',\n",
       " '0faacc2f-d383-4f7c-a849-f44e642d429a',\n",
       " '0b20c8ae-b46d-46ae-bcb0-d19e0016614c',\n",
       " '1bd34258-bdb9-4899-9ecd-ce0d00a61b64',\n",
       " '48b051b1-0728-4096-a596-35f5dd6b8835',\n",
       " '91564e6c-09b5-4b6d-9f20-3101b66f0827',\n",
       " '8917d249-c6cb-40c3-a138-d6763430a417',\n",
       " '08a77244-54e9-4aba-b1a9-adcaccd0b036',\n",
       " '9b026c9a-beb0-4f13-9ec7-2ea108206411',\n",
       " '8a44e6b5-a9c7-4795-b4c9-62dcb63eafa0',\n",
       " 'd9fd283c-b0f8-45a7-be94-e843e169b1c9',\n",
       " 'c89379a0-1a20-4f29-b4e4-50ef3593f5ed',\n",
       " '32e3bb39-bf1d-4502-b228-3d416fb9b146',\n",
       " 'c2980aec-14f2-4f56-aba5-c81d4b5e1381',\n",
       " 'a104a829-c00c-4412-864d-040d777e17ce',\n",
       " 'b0624800-cac4-401a-90a7-bdb370e1b624',\n",
       " 'da9ffec9-2b8e-408c-bd6c-6453ac29d032',\n",
       " 'c6b69b5b-b1c6-427a-9daf-e574e0e14998',\n",
       " '579ae1f8-fdda-4f56-a209-1be6872a0f7f',\n",
       " 'c53f32da-f9aa-4b8e-bf20-ce56ba9581df',\n",
       " '28f63e26-dd50-4e8c-ad31-065c3284ccef',\n",
       " 'f88b4c7a-cf49-4da6-8d89-f089cc8bd023',\n",
       " 'bc5fca21-08fe-44d3-bb0d-ec61420dafb4',\n",
       " '1ccd8080-1f49-4172-b93d-ce1377ab9a1c',\n",
       " 'd7c1de89-7037-4218-ab79-5db714c42100',\n",
       " '9f6b7746-1adf-4382-b40e-24091555c111',\n",
       " '2efcc46f-ed83-494f-a057-47393b133332',\n",
       " '4e6f2892-38c7-4249-a3d9-fed2a4b739bf',\n",
       " 'efd4c2b1-415a-4e89-b228-33da2bf1e3c3',\n",
       " '3550d112-35f9-47e0-ab6c-c1ded5c88808',\n",
       " '9a7d3b21-96ea-46de-9193-9a1e16c11f96',\n",
       " 'e502b4cf-8ef5-4b58-87dc-04bfd267d1b3',\n",
       " '51276a11-abac-4350-b980-effe6d057064',\n",
       " '742da97d-ca88-4edc-a6ae-659511a946b6',\n",
       " '2e2ff1b1-23b8-4aa4-b712-565374a6e38d',\n",
       " 'bb717d60-1cb8-4838-a2ba-789c5a398e9f',\n",
       " 'c8c6f841-5773-401f-91f7-d602a7ff1470',\n",
       " '203b5f80-ef7c-4d61-9389-f231993cbf85',\n",
       " 'c9ad0a0c-e867-4b54-a0ac-fa0b3347d55a',\n",
       " 'd1ed6e1a-90df-46e1-b043-ea1b2b0e8040',\n",
       " '5665e648-22dd-45f2-83e8-e50ca27b7fab',\n",
       " 'f2edd30f-9406-4ee7-89c5-93120867f20b',\n",
       " 'cd600f84-aabd-4ccc-bde1-7e22390f0c87',\n",
       " 'a376fb6e-05cd-4bf8-bc17-979ba5a3b41c',\n",
       " '1fbfca98-0d4c-489c-b050-f443f931cae4',\n",
       " 'b52e751b-3863-42b4-9123-1f851a28b7bb',\n",
       " '4199b1bc-bac7-488c-bde2-1360e300889e',\n",
       " '0e49f88d-e891-4c26-874c-0000e04ecea0',\n",
       " '3113041e-bf49-4bb5-85c9-f644b86cdd65',\n",
       " '64e7cb72-e679-4377-ba63-b6f60a5e9815',\n",
       " 'd14993f8-403f-4862-8a6d-505128a157c1',\n",
       " 'deb6eafa-0382-44ed-a025-85afac0b3045',\n",
       " '84644d86-fb23-4743-89e8-7106eb877d9a',\n",
       " '108f11e2-6bdb-4969-8585-fda68eae4acb',\n",
       " 'b9076e9f-17f6-475e-a0e4-fa0e2098f01d',\n",
       " 'fdd1541e-3289-48c3-b34b-27efaeb0929b',\n",
       " '18fa7b9e-1dc1-41b2-8768-db9d9044fd4c',\n",
       " '32f88d36-2ffd-4627-956c-8b47ca7f3be9',\n",
       " '63167d06-279d-457a-85fe-6a4904db753d',\n",
       " 'b1b5f2b4-58c5-4a5e-af95-23f41620034d',\n",
       " 'a0bc2499-9c2a-4e7a-b249-69a73a91d78a',\n",
       " 'c8252c12-004e-4591-8c92-6db1d2f40210']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "vector_store = WeaviateVectorStore(\n",
    "    client=client, index_name=collection_name, embedding=embeddings, text_key=\"text\"\n",
    ")\n",
    "\n",
    "vector_store.add_documents(split_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Perform the search\n",
    "\n",
    "We can now perform a similarity search. This will return the most similar documents to the query text, based on the embeddings stored in Weaviate and an equivalent embedding generated from the query text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1:\n",
      "To console himself, he drew upon his experiences over the Saharan desert to write and illustrate what would become his most famous book, The Little Prince (1943). Mystical and enchanting, this small book has fascinated both children and adults for decades. In the book, a pilot is stranded in the\n"
     ]
    }
   ],
   "source": [
    "from utils.weaviate_vectordb import WeaviateSearch\n",
    "\n",
    "query = \"What is the little prince about?\"\n",
    "searcher = WeaviateSearch(vector_store)\n",
    "docs = searcher.similarity_search(query, k=1)\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add filters, which will either include or exclude results based on the filter conditions. (See [more filter examples](https://weaviate.io/developers/weaviate/search/filters).)\n",
    "\n",
    "It is also possible to provide `k`, which is the upper limit of the number of results to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': None, 'author': None, 'source': None, 'order': None}, page_content='To console himself, he drew upon his experiences over the Saharan desert to write and illustrate what would become his most famous book, The Little Prince (1943). Mystical and enchanting, this small book has fascinated both children and adults for decades. In the book, a pilot is stranded in the')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weaviate.classes.query import Filter\n",
    "\n",
    "filter_query = Filter.by_property(\"text\").equal(\"In the book, a pilot is\")\n",
    "\n",
    "searcher.similarity_search(\n",
    "    query=query,\n",
    "    filter_query=filter_query,\n",
    "    k=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify Result Similarity\n",
    "\n",
    "When performing similarity searches, you might want to know not just which documents are similar, but how similar they are. Weaviate provides this information through a relevance score.\n",
    "> 💡 Tip: The relevance score helps you understand the relative similarity between search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752 : To console himself, he drew upon his experiences over the Saharan desert to write and illustrate what would become his most famous book, The Little Prince (1943). Mystical and enchanting, this small book has fascinated both children and adults for decades. In the book, a pilot is stranded in the\n",
      "0.692 : In the book, a pilot is stranded in the midst of the Sahara where he meets a tiny prince from another world traveling the universe in order to understand life. In the book, the little prince discovers the true meaning of life. At the end of his conversation with the Little Prince, the aviator\n",
      "0.652 : The Little Prince\n",
      "Written By Antoine de Saiot-Exupery (1900〜1944)\n",
      "0.596 : [ Chapter 7 ]\n",
      "- the narrator learns about the secret of the little prince‘s life\n",
      "0.590 : [ Chapter 3 ]\n",
      "- the narrator learns more about from where the little prince came\n"
     ]
    }
   ],
   "source": [
    "docs = searcher.similarity_search_with_score(query, k=5)\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"{doc[1]:.3f}\", \":\", doc[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`similarity_search` uses Weaviate's [hybrid search](https://weaviate.io/developers/weaviate/api/graphql/search-operators#hybrid).\n",
    "\n",
    "A hybrid search combines a vector and a keyword search, with `alpha` as the weight of the vector search. The `similarity_search` function allows you to pass additional arguments as kwargs. See this [reference doc](https://weaviate.io/developers/weaviate/api/graphql/search-operators#hybrid) for the available arguments.\n",
    "\n",
    "So, you can perform a pure keyword search by adding `alpha=0` as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'title': None, 'order': None, 'source': None, 'author': None}, page_content='\"Yes?\" said the little prince, who did not understand what the conceited man was talking about. \\n\"Clap your hands, one against the other,\" the conceited man now directed him. \\nThe little prince clapped his hands. The conceited man raised his hat in a modest salute.')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = searcher.similarity_search(query, alpha=0)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any data added through `langchain-weaviate` will persist in Weaviate according to its configuration. \n",
    "\n",
    "WCS instances, for example, are configured to persist data indefinitely, and Docker instances can be set up to persist data in a volume. Read more about [Weaviate's persistence](https://weaviate.io/developers/weaviate/configuration/persistence)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-tenancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Multi-tenancy](https://weaviate.io/developers/weaviate/concepts/data#multi-tenancy) allows you to have a high number of isolated collections of data, with the same collection configuration, in a single Weaviate instance. This is great for multi-user environments such as building a SaaS app, where each end user will have their own isolated data collection.\n",
    "\n",
    "To use multi-tenancy, the vector store need to be aware of the `tenant` parameter. \n",
    "\n",
    "So when adding any data, provide the `tenant` parameter as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-Feb-05 08:44 PM - langchain_weaviate.vectorstores - INFO - Tenant tenant1 does not exist in index LangChain_c0dccb3967144ac78580871e6187289c. Creating tenant.\n"
     ]
    }
   ],
   "source": [
    "# 2. Create a vector store with a specific tenant\n",
    "vector_store_with_tenant = WeaviateVectorStore.from_documents(\n",
    "    docs, embeddings, client=client, tenant=\"tenant1\"  # specify the tenant name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Yes?\" said the little prince, who did not understand what the conceited man was talking about. \n",
      "\"Clap your hands, one against the other,\" the conceited man now directed him. \n",
      "The little prince clapped his hands. The conceited man raised his hat in a modest salute.\n",
      "[ Chapter 6 ]\n",
      "- the little prince and the narrator talk about sunsets\n",
      "[ Chapter 25 ]\n",
      "- finding a well, the narrator and the little prince discuss his return to his planet\n",
      "\"Men,\" said the little prince, \"set out on their way in express trains, but they do not know what they are looking for. Then they rush about, and get excited, and turn round and round...\"\n"
     ]
    }
   ],
   "source": [
    "results = vector_store_with_tenant.similarity_search(\n",
    "    query, tenant=\"tenant1\"  # use the same tenant name\n",
    ")\n",
    "\n",
    "for doc in results:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-Feb-05 08:44 PM - langchain_weaviate.vectorstores - INFO - Tenant tenant1 does not exist in index LangChain_0c0065f67f854246ba3abad709a22887. Creating tenant.\n"
     ]
    }
   ],
   "source": [
    "vector_store_with_tenant = WeaviateVectorStore.from_documents(\n",
    "    docs, embeddings, client=client, tenant=\"tenant1\", mt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And when performing queries, provide the `tenant` parameter also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': None, 'order': None, 'source': None, 'author': None}, page_content='\"Yes?\" said the little prince, who did not understand what the conceited man was talking about. \\n\"Clap your hands, one against the other,\" the conceited man now directed him. \\nThe little prince clapped his hands. The conceited man raised his hat in a modest salute.'),\n",
       " Document(metadata={'title': None, 'author': None, 'source': None, 'order': None}, page_content='[ Chapter 6 ]\\n- the little prince and the narrator talk about sunsets'),\n",
       " Document(metadata={'title': None, 'author': None, 'source': None, 'order': None}, page_content='[ Chapter 25 ]\\n- finding a well, the narrator and the little prince discuss his return to his planet\\n\"Men,\" said the little prince, \"set out on their way in express trains, but they do not know what they are looking for. Then they rush about, and get excited, and turn round and round...\"')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store_with_tenant.similarity_search(query, tenant=\"tenant1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever options\n",
    "\n",
    "Weaviate can also be used as a retriever\n",
    "\n",
    "### Maximal marginal relevance search (MMR)\n",
    "\n",
    "In addition to using similaritysearch  in the retriever object, you can also use `mmr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Monthly unique traces usage limit exceeded\"}')trace=336c8845-9e15-4403-9adf-416c9faeace6,id=336c8845-9e15-4403-9adf-416c9faeace6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'title': None, 'order': None, 'source': None, 'author': None}, page_content='To console himself, he drew upon his experiences over the Saharan desert to write and illustrate what would become his most famous book, The Little Prince (1943). Mystical and enchanting, this small book has fascinated both children and adults for decades. In the book, a pilot is stranded in the')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"mmr\")\n",
    "retriever.invoke(query)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A known limitation of large language models (LLMs) is that their training data can be outdated, or not include the specific domain knowledge that you require.\n",
    "\n",
    "Take a look at the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Monthly unique traces usage limit exceeded\"}')trace=e0bc9d89-3169-4244-abf4-21bd19844869,id=e0bc9d89-3169-4244-abf4-21bd19844869; trace=336c8845-9e15-4403-9adf-416c9faeace6,id=336c8845-9e15-4403-9adf-416c9faeace6\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Monthly unique traces usage limit exceeded\"}')trace=69fe8c7d-5893-4108-8f51-5d23cf4f4876,id=69fe8c7d-5893-4108-8f51-5d23cf4f4876; trace=69fe8c7d-5893-4108-8f51-5d23cf4f4876,id=c99ef27d-ef8c-4a21-85e3-8fc312805a23; trace=e0bc9d89-3169-4244-abf4-21bd19844869,id=e0bc9d89-3169-4244-abf4-21bd19844869\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Monthly unique traces usage limit exceeded\"}')trace=69fe8c7d-5893-4108-8f51-5d23cf4f4876,id=897dc3e6-2841-4fef-b430-44998d0ac711; trace=69fe8c7d-5893-4108-8f51-5d23cf4f4876,id=3bee1fc4-5bb0-4465-be1c-f66c63b62819; trace=69fe8c7d-5893-4108-8f51-5d23cf4f4876,id=6a46fe84-e6ff-4fc1-ab8e-cd39c4e2e880; trace=69fe8c7d-5893-4108-8f51-5d23cf4f4876,id=c99ef27d-ef8c-4a21-85e3-8fc312805a23\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Monthly unique traces usage limit exceeded\"}')trace=53121f3c-bd0b-4361-b33d-dcce6e7e8154,id=53121f3c-bd0b-4361-b33d-dcce6e7e8154; trace=53121f3c-bd0b-4361-b33d-dcce6e7e8154,id=c4cb3b22-adc2-4db6-9dd3-801fa3d80f3d; trace=53121f3c-bd0b-4361-b33d-dcce6e7e8154,id=3034443b-0cc4-48f3-8f76-55ff958fbb55; trace=53121f3c-bd0b-4361-b33d-dcce6e7e8154,id=116be394-ce7a-4d13-8284-7a789fec5d48; trace=69fe8c7d-5893-4108-8f51-5d23cf4f4876,id=69fe8c7d-5893-4108-8f51-5d23cf4f4876; trace=69fe8c7d-5893-4108-8f51-5d23cf4f4876,id=897dc3e6-2841-4fef-b430-44998d0ac711; trace=69fe8c7d-5893-4108-8f51-5d23cf4f4876,id=3bee1fc4-5bb0-4465-be1c-f66c63b62819; trace=69fe8c7d-5893-4108-8f51-5d23cf4f4876,id=6a46fe84-e6ff-4fc1-ab8e-cd39c4e2e880\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Monthly unique traces usage limit exceeded\"}')trace=53121f3c-bd0b-4361-b33d-dcce6e7e8154,id=bbc5712f-49ab-43c5-9c15-e8723e8f55c8; trace=53121f3c-bd0b-4361-b33d-dcce6e7e8154,id=a3490627-774f-477a-91d1-0627b34dbbf1; trace=53121f3c-bd0b-4361-b33d-dcce6e7e8154,id=3034443b-0cc4-48f3-8f76-55ff958fbb55; trace=53121f3c-bd0b-4361-b33d-dcce6e7e8154,id=c4cb3b22-adc2-4db6-9dd3-801fa3d80f3d\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithRateLimitError: Rate limit exceeded for https://api.smith.langchain.com/runs/multipart. HTTPError('429 Client Error: Too Many Requests for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Monthly unique traces usage limit exceeded\"}')trace=53121f3c-bd0b-4361-b33d-dcce6e7e8154,id=8d20c10c-35b1-4233-a3ba-5f0ef3c46f1f; trace=53121f3c-bd0b-4361-b33d-dcce6e7e8154,id=53121f3c-bd0b-4361-b33d-dcce6e7e8154; trace=53121f3c-bd0b-4361-b33d-dcce6e7e8154,id=a3490627-774f-477a-91d1-0627b34dbbf1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The Little Prince,\" written by Antoine de Saint-Exupéry, is a philosophical tale that explores themes of love, loss, friendship, and the nature of human relationships. The story follows a young prince who travels from his home asteroid, B-612, to various planets, each inhabited by a different character that embodies certain adult traits and societal flaws.\n",
      "\n",
      "The narrative begins with a pilot stranded in the Sahara Desert who meets the Little Prince. Through their conversations, the prince shares his experiences and the lessons he has learned during his travels. He encounters a king, a vain man, a drunkard, a businessman, a geographer, and a fox, each representing different aspects of adult behavior and societal norms.\n",
      "\n",
      "One of the central themes of the book is the contrast between the innocence and purity of childhood and the often superficial concerns of adulthood. The Little Prince's love for a rose on his home planet symbolizes the importance of relationships and the idea that what truly matters is often invisible to the eye. The story emphasizes the value of seeing with the heart rather than just the eyes.\n",
      "\n",
      "Ultimately, \"The Little Prince\" is a poignant reflection on the nature of human existence, encouraging readers to cherish their connections with others and to maintain a sense of wonder and imagination throughout life.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "result = llm.invoke(query)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector stores complement LLMs by providing a way to store and retrieve relevant information. This allow you to combine the strengths of LLMs and vector stores, by using LLM's reasoning and linguistic capabilities with vector stores' ability to retrieve relevant information.\n",
    "\n",
    "Two well-known applications for combining LLMs and vector stores are:\n",
    "- Question answering\n",
    "- Retrieval-augmented generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Answering with Sources\n",
    "\n",
    "Question answering in langchain can be enhanced by the use of vector stores. Let's see how this can be done.\n",
    "\n",
    "This section uses the `RetrievalQAWithSourcesChain`, which does the lookup of the documents from an Index. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can construct the chain, with the retriever specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = WeaviateSearch(vector_store)\n",
    "\n",
    "chain = searcher.create_qa_chain(\n",
    "    llm=llm, retriever=vector_store.as_retriever(), chain_type=\"stuff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'The Little Prince is about a pilot who is stranded in the Sahara desert and meets a tiny prince from another world. The little prince travels the universe to understand life and, through their conversations, discovers the true meaning of life. The book is mystical and enchanting, appealing to both children and adults.\\n\\n',\n",
       " 'sources': 'None'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\"question\": query},\n",
    "    return_only_outputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval-Augmented Generation\n",
    "\n",
    "Another very popular application of combining LLMs and vector stores is retrieval-augmented generation (RAG). This is a technique that uses a retriever to find relevant information from a vector store, and then uses an LLM to provide an output based on the retrieved data and a prompt.\n",
    "\n",
    "We begin with a similar setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to construct a template for the RAG model so that the retrieved information will be populated in the template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question}\\nContext: {context}\\nAnswer:\\n\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Little Prince is a mystical and enchanting story about a pilot stranded in the Sahara who encounters a young prince from another planet. The narrative explores themes of love, loss, and the importance of relationships, emphasizing that \"what is essential is invisible to the eye.\" Through his journey, the little prince learns valuable lessons about taming and the significance of the connections we make.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-BXw0bE1H-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
